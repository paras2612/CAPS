# -*- coding: utf-8 -*-
"""Feature_Selection_Methods.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lYA5pnAKDyo0W7MfmNbQK2OnwKu8YmUM
"""

!pip install skfeature-chappers
!pip install mlxtend

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_regression, mutual_info_classif

def clean_dataset(df):
    assert isinstance(df, pd.DataFrame), "df needs to be a pd.DataFrame"
    df.dropna(inplace=True)
    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)
    return df[indices_to_keep].astype(np.float64)

import os
from skfeature.function.similarity_based import fisher_score
from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_selection import RFE
from sklearn.tree import DecisionTreeRegressor
from sklearn.feature_selection import VarianceThreshold
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestRegressor
import warnings
from sklearn.feature_selection import chi2
from sklearn.preprocessing import LabelEncoder
import numpy as np, scipy.stats as st
warnings.filterwarnings("ignore")


path = "/content/drive/MyDrive/SWAT/SWAT_Data/"
opath = "/content/drive/MyDrive/SWAT/SWAT_DailyFeatures/"
files = sorted(os.listdir(path))
df = pd.DataFrame()

for i in files:
  if("csv" in i):
    dataset = pd.read_csv(path+i)
    df = df.append(dataset)
    break
    #dataset= pd.read_csv("/content/AllDataForDay1.csv")
    #dataset_cols = pd.read_csv("/content/AllDataForDay1.csv").columns
    #dataset.columns = dataset_cols
    # dataset = clean_dataset(dataset)
    # X= dataset.iloc[:,0:38]
    # y= dataset.iloc[:,38].values
    # full_data= X.copy()
    # full_data["WYLDmm"]= y
    # full_data.head(2)
    # #Filter Method
    importances = mutual_info_regression(X.values,y)
    feat_importances = pd.Series(importances, dataset.columns[0:len(dataset.columns)-2])
    selected_features = list(pd.DataFrame(feat_importances[feat_importances>0].sort_values()).index)
    # with open(opath+i.split(".")[0]+"_FilterMethod.txt" , 'w') as fp:
    #       fp.writelines(str(selected_features))
    '''
    ranks = fisher_score.fisher_score(X.values,y)
    feat_importances = pd.Series(ranks, dataset.columns[0:len(dataset.columns)-2])
    selected_features = list(pd.DataFrame(feat_importances[feat_importances<=20].sort_values()).index)
    with open(opath+i.split(".")[0]+"_FisherScore.txt" , 'w') as fp:
          fp.writelines(str(selected_features))
    
    corr = dataset.corr()
    a= corr['WYLDmm'].dropna()
    selected_features=list(pd.DataFrame(a[a>0].sort_values()).index)
    with open(opath+i.split(".")[0]+"_Correlation.txt" , 'w') as fp:
          fp.writelines(str(selected_features))
    
    v_threshold = VarianceThreshold(threshold=0)
    v_threshold.fit(X)
    selected_features=list(X.columns[v_threshold.get_support()])
    with open(opath+i.split(".")[0]+"_VarianceThreshold.txt" , 'w') as fp:
          fp.writelines(str(selected_features))
    
    mean_abs_diff = np.sum(np.abs(X-np.mean(X,axis=0)), axis=0)/X.shape[0]
    selected_features = list(pd.DataFrame(mean_abs_diff[mean_abs_diff>0].sort_values()).index)
    with open(opath+i.split(".")[0]+"_MAD.txt" , 'w') as fp:
          fp.writelines(str(selected_features))
    
    knn = KNeighborsClassifier(n_neighbors=20)
    sfs = SequentialFeatureSelector(knn, n_features_to_select=20,direction='forward')
    sfs.fit(X, y)
    selected_features = list(X.columns[sfs.get_support()])
    with open(opath+i.split(".")[0]+"_FFS.txt" , 'w') as fp:
          fp.writelines(str(selected_features))
    
    knn = KNeighborsClassifier(n_neighbors=20)
    sfs = SequentialFeatureSelector(knn, n_features_to_select=20,direction='backward')
    sfs.fit(X, y)
    selected_features = list(X.columns[sfs.get_support()])
    with open(opath+i.split(".")[0]+"_BFS.txt" , 'w') as fp:
          fp.writelines(str(selected_features))

    rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=20)
    a = rfe.fit(X.values,y)
    selected_features = list(X.columns[a.get_support()])
    with open(opath+i.split(".")[0]+"_RFS.txt" , 'w') as fp:
          fp.writelines(str(selected_features))'''
    
    '''lr = LinearRegression().fit(X.values,y)
    model = SelectFromModel(lr,prefit=True)
    selected_features = list(X.columns[model.get_support()])
    with open(opath+i.split(".")[0]+"_Lasso.txt" , 'w') as fp:
          fp.writelines(str(selected_features))
    
    model = RandomForestRegressor(n_estimators=500)
    model.fit(X.values,y)
    importances = model.feature_importances_
    feature_df = pd.DataFrame({"Features":X.columns,"Importances":importances})
    feature_df = feature_df.sort_values("Importances")
    feature_df = feature_df[feature_df['Importances']>0]
    selected_features = list(feature_df['Features'].values)
    with open(opath+i.split(".")[0]+"_RF.txt" , 'w') as fp:
          fp.writelines(str(selected_features))'''
    
  print("Done for ",i)

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
import statsmodels.api as sm


k_best = SelectKBest(chi2, k=38)

#X = df[['CFH', 'EPCO', 'ALPHA_BF', 'Ave..AW.Incl..Rock.Frag1', 'SLSOIL', 'GWQMN', 'Ksat...est.........mm.hr.1', 'CFDEC', 'R2ADJ', 'ESCO', 'Crack.volume.potential.of.soil', 'HRU_SLP', 'DEP_IMP', 'DIS_STREAM', 'GW_DELAY', 'SLSUBBSN', 'SURLAG', 'Ksat...est.........mm.hr.3', 'CANMX']]
#X=df[['REVAPMN', 'RCHRG_DP', 'SURLAG', 'GW_REVAP', 'GW_SPYLD', 'R2ADJ', 'CFDEC', 'HRU_SLP', 'OV_N', 'ALPHA_BF_D', 'DEP_IMP', 'EPCO', 'LAT_TTIME', 'CFH', 'SLSOIL', 'CF', 'HRU_FR', 'SLSUBBSN', 'DIS_STREAM', 'ESCO', 'CANMX']]
#X = df[['HRU_SLP', 'OV_N', 'Depth.................mm.1', 'Ksat...est.........mm.hr.3', 'Depth.................mm.3', 'Ave..AW.Incl..Rock.Frag2', 'Bulk.Density.Moist..g.cc.1', 'Ave..AW.Incl..Rock.Frag1', 'Bulk.Density.Moist..g.cc.2', 'CN2', 'AREAkm2', 'Ave..AW.Incl..Rock.Frag3', 'Bulk.Density.Moist..g.cc.3', 'SLSUBBSN']]
#X = df[['Depth.................mm.1', 'Depth.................mm.2', 'Depth.................mm.3', 'Bulk.Density.Moist..g.cc.1', 'Bulk.Density.Moist..g.cc.2', 'Bulk.Density.Moist..g.cc.3', 'Ave..AW.Incl..Rock.Frag1', 'Ave..AW.Incl..Rock.Frag2', 'Ave..AW.Incl..Rock.Frag3', 'Ksat...est.........mm.hr.1', 'Ksat...est.........mm.hr.2', 'Ksat...est.........mm.hr.3', 'CN2', 'GW_DELAY', 'ALPHA_BF', 'GWQMN', 'GW_REVAP', 'REVAPMN', 'RCHRG_DP']]
#X = df[['REVAPMN', 'RCHRG_DP', 'GW_SPYLD', 'ALPHA_BF_D', 'HRU_FR', 'DIS_STREAM', 'SLSUBBSN', 'HRU_SLP', 'OV_N', 'LAT_TTIME', 'SLSOIL', 'CANMX', 'ESCO', 'EPCO', 'DEP_IMP', 'CF', 'CFH', 'CFDEC', 'SURLAG', 'R2ADJ']]
#X = df[['Depth.................mm.1', 'Depth.................mm.2', 'Depth.................mm.3', 'Bulk.Density.Moist..g.cc.1', 'Bulk.Density.Moist..g.cc.2', 'Bulk.Density.Moist..g.cc.3', 'Ave..AW.Incl..Rock.Frag1', 'Ave..AW.Incl..Rock.Frag2', 'Ave..AW.Incl..Rock.Frag3', 'Ksat...est.........mm.hr.1', 'Ksat...est.........mm.hr.2', 'Ksat...est.........mm.hr.3', 'CN2', 'HRU_FR', 'DIS_STREAM', 'SLSUBBSN', 'HRU_SLP', 'OV_N', 'LAT_TTIME', 'SLSOIL']]
#X = df[['Ave..AW.Incl..Rock.Frag1', 'Ave..AW.Incl..Rock.Frag3', 'Ave..AW.Incl..Rock.Frag2', 'HRU_SLP', 'HRU_FR']]
#X = df[['Ave..AW.Incl..Rock.Frag2', 'Ksat...est.........mm.hr.2', 'Ave..AW.Incl..Rock.Frag3', 'SLSUBBSN', 'Ksat...est.........mm.hr.3', 'Ave..AW.Incl..Rock.Frag1', 'Ksat...est.........mm.hr.1', 'Bulk.Density.Moist..g.cc.2', 'Bulk.Density.Moist..g.cc.3', 'Depth.................mm.1', 'Bulk.Density.Moist..g.cc.1', 'Depth.................mm.2', 'Depth.................mm.3', 'OV_N', 'CN2', 'HRU_SLP', 'HRU_FR']]
#X = df[['DIS_STREAM','SLSOIL','AREAkm2', 'Ave..AW.Incl..Rock.Frag3', 'Bulk.Density.Moist..g.cc.2', 'Ave..AW.Incl..Rock.Frag1', 'Ave..AW.Incl..Rock.Frag2', 'Ksat...est.........mm.hr.1', 'Depth.................mm.3', 'Ksat...est.........mm.hr.2', 'Bulk.Density.Moist..g.cc.1', 'Ksat...est.........mm.hr.3', 'Bulk.Density.Moist..g.cc.3', 'HRU_SLP', 'Depth.................mm.2', 'Depth.................mm.1', 'OV_N', 'CN2', 'SLSUBBSN', 'HRU_FR']]
colx = df.columns[:-1]
X = df[colx]
y = df['WYLDmm']
est = sm.OLS(y, X)
est2 = est.fit()
#print(est2.summary())
a = pd.DataFrame(est2.pvalues[est2.pvalues<0.05])
print(a.index)
#chi_scores = chi2(X,y)
# label_encoder = LabelEncoder()
# y = label_encoder.fit_transform(y)
# k_best.fit_transform(X, y)
# p_values = pd.DataFrame({'column': X.columns, 'p_value':
# k_best.pvalues_}).sort_values('p_value')
# p_values[p_values['p_value'] < .05]

#['Crack.volume.potential.of.soil', 'GW_DELAY', 'ALPHA_BF', 'GWQMN','GW_REVAP', 'REVAPMN', 'RCHRG_DP', 'GW_SPYLD', 'DIS_STREAM', 'CANMX','ESCO', 'EPCO', 'DEP_IMP', 'CF', 'CFH', 'CFDEC', 'SURLAG', 'R2ADJ']

!pip install causal-ccm

X = df[['GW_DELAY']]

from causal_ccm.causal_ccm import ccm
ccm1 = ccm(X, y) # define ccm with X, Y time Series

ccm1.causality()

IG = 3
FS = 1
Corr = 5
FFS = 6
BFS = 1
RFS = 7
Lasso = 4
RFI = 7
Causal = 8

p_values = pd.Series(k_best.pvalues_,index = X.columns)
p_values.sort_values(ascending = False , inplace = True)
p_values.plot.bar()

chi_scores[1]

opath = "/content/drive/MyDrive/SWAT/SWAT_DailyFeatures/"
files = os.listdir(opath)
features = []
for i in files:
  if('FilterMethod' in i):
    print(i)
    with open(opath+i) as f:
      features.extend(eval(f.read()))
print(features)

from collections import Counter
a = Counter(features)
dict(sorted(a.items(), key=lambda item: item[1]))

"""# Filter Methods

Information Gain
"""

importances = mutual_info_regression(X.values,y)
feat_importances = pd.Series(importances, dataset.columns[0:len(dataset.columns)-2])
list(pd.DataFrame(feat_importances[feat_importances>0].sort_values()).index)

TLSS1,2,3, GWV1,3,

"""Fisher's Score"""

!pip install skfeature-chappers

from skfeature.function.similarity_based import fisher_score

ranks = fisher_score.fisher_score(X.values,y)

feat_importances = pd.Series(ranks, dataset.columns[0:len(dataset.columns)-2])
feat_importances[feat_importances<=20].sort_values()

"""Correlation coefficient"""

import seaborn as sns

corr = dataset.corr()
a= corr['WYLDmm'].dropna()
a[a>0].sort_values()

"""Variance Threshold"""

from sklearn.feature_selection import VarianceThreshold

v_threshold = VarianceThreshold(threshold=0)
v_threshold.fit(X)
list(X.columns[v_threshold.get_support()])

"""Mean Absolute Difference"""

mean_abs_diff = np.sum(np.abs(X-np.mean(X,axis=0)), axis=0)/X.shape[0]
mean_abs_diff[mean_abs_diff>0].sort_values()

"""# Wrapper Methods

Forward Feature Selection
"""



from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=20)
sfs = SequentialFeatureSelector(knn, n_features_to_select=20,direction='forward')
sfs.fit(X, y)
sfs.get_support()

list(X.columns[sfs.get_support()])

"""Backward Feature Elimination"""

from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=20)
sfs = SequentialFeatureSelector(knn, n_features_to_select=20,direction='backward')
sfs.fit(X, y)
sfs.get_support()

list(X.columns[sfs.get_support()])

"""Exhaustive Feature Selection"""

from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS
knn = KNeighborsClassifier(n_neighbors=20)

efs1 = EFS(knn, 
           min_features=20,
           max_features=20,
           scoring='accuracy',
           print_progress=True,
           cv=2)
efs1 = efs1.fit(X.values, y,custom_feature_names = X.columns)

efs1.best_feature_names_

"""Recursive Feature Elimination"""

from sklearn.feature_selection import RFE
from sklearn.tree import DecisionTreeRegressor

rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=20)
a = rfe.fit(X.values,y)

rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=20)
a = rfe.fit(X.values,y)
list(X.columns[a.get_support()])

"""# Embedded Methods

LASSO Regulraization
"""

from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import SelectFromModel

lr = LinearRegression().fit(X.values,y)
model = SelectFromModel(lr,prefit=True)

X_new = model.transform(X)

list(X.columns[model.get_support()])

"""Random Forest Importance"""

from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=500)

model.fit(X.values,y)

importances = model.feature_importances_
feature_df = pd.DataFrame({"Features":X.columns,"Importances":importances})
feature_df = feature_df.sort_values("Importances")
feature_df = feature_df[feature_df['Importances']>0]

feature_df

